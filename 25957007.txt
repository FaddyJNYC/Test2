1The term hermeneutics refers to the art of interpreting written texts
such as holy scriptures. The key problem for hermeneutics rests on
developing criteria for deciding when an interpretation is correct.
This problem is not restricted to the interpretation of ancient texts.
When talking to you, I cannot access your mind to check whether my
interpretation of what you have just said corresponds to what you
meant. I can invent a coherent story or narrative, but I can never
independently verify my interpretations (Frith & Wentzer, 2013).
Nevertheless, people seem to understand each other most the time. How
is this achieved? In this paper, we suggest the criteria for
evaluating and updating my interpretation of your behaviour are
exactly the same criteria that underlie action and perception in
general; namely, the minimisation of prediction error or (variational)
free energy.In a companion paper (Friston and Frith, 2015), we
considered communication in terms of inference about others, based on
the notion that we model and predict our sensations – sensations that
are generated by other agents like ourselves. This leads to a view of
communication based on a generative model or narrative that is shared
by agents who exchange sensory signals. Given a shared narrative,
communication can then be cast as Wilson & Wilson, 2005), by
selectively attending and attenuating sensory information. Attending
to exteroceptive sensations enables the shared narrative to predict
the sensory input generated by another (while listening). Conversely,
attenuating exteroceptive input enables one to articulate the
narrative by realising proprioceptive predictions (while speaking).
Using simulations, we demonstrated this turn taking by assuming that
both agents possessed the same generative model. In this paper, we
consider how and why generative models learned by agents – who
exchange sensory signals – become the same (shared) model.Our
underlying premise is that we are trying to model the causes of our
sensations – and adjust those models to maximise Bayesian model
evidence or, equivalently, minimise surprise (Brown & Brün, 2012;
Kilner, Friston, & Frith, 2007). This perspective on action and
perception has broad explanatory power in several areas of cognitive
neuroscience – and enjoys support from several lines of
neuroanatomical and neurophysiological evidence (Egner & Summerfield,
2013; Rao & Ballard, 1999; Srinivasan, Laughlin, & Dubs, 1982). In
communication and the interpretation of intent, the very notion of In
our previous paper, we focused on the dynamical phenomena that emerge
when two dynamical systems try to predict each other. Mathematically,
this dynamical coupling is called Barreto, Josic, Morales, Sander, &
So, 2003; Hunt, Ott, & Yorke, 1997). Generalised synchrony was
famously observed by Huygens in his studies of pendulum clocks – that
synchronized themselves through the imperceptible motion of beams from
which they were suspended (Huygens, 1673). This nicely illustrates the
We will consider a special case of generalized synchronization;
namely, Fig. 1).The treatment of communication in this paper is rather
abstract and borrows mathematical concepts from dynamical systems
theory. Although we will use birdsong as a vehicle to illustrate the
ideas, we do not pretend this is a meaningful model of linguistic
communication (or indeed songbirds). Rather, we try to understand the
dynamic coordination of richly structured behaviours, such as singing
and dancing, without ascribing any (semantic) meaning or syntax to
sensory exchanges. Having said this, there is growing interest in
applying the principles of predictive coding to language: e.g., (Arnal
& Giraud, 2012; Hickok, 2013; Pickering & Clark, 2014; Wang, Mathalon,
et al., 2014) – and understanding the algebra of dynamical systems in
terms of communication; e.g., (Scott-Phillips & Blythe, 2013).
Furthermore, predictive coding is starting to shed light on spectral
asymmetries – in coupling within the auditory hierarchy – evident in
electrophysiological studies of speech processing (Arnal, Wyart, &
Giraud, 2011).This paper comprises five sections. The first sections
reprise the material in (Friston and Frith, 2015), which provides a
brief review of active inference and predictive coding in
communication. In the second section, we described the particular
(birdsong) model used to illustrate communicative inference. This
model has been used previously to illustrate several phenomena in
perception; such as perceptual learning, repetition suppression, and
the recognition of stimulus streams with deep hierarchical structure
(Friston & Kiebel, 2009; Kiebel, Daunizeau, & Friston, 2008). In the
third section, we provide a simple illustration of omission related
responses – that are ubiquitous in neurophysiology and illustrate the
basic nature of predictive coding. In the fourth section, we use this
model to simulate two (identical) birds that are singing to themselves
(and each other) and examine the conditions under which generalised
synchrony emerges. In the final section, we repeat the simulations
using two birds that start off with different generative models. We
will see that perceptual learning produces a convergence of the two
generative models over time – leading to the emergence of generalised
synchrony and implicit communication. We offer this as a solution to
the problem of hermeneutic inference that can be resolved by
neuronally plausible schemes – with the single imperative to minimise
prediction error or free energy.2Recent advances in theoretical
neuroscience have produced a paradigm shift in cognitive neuroscience.
This shift is away from the brain as a passive filter of sensations –
or an elaborate stimulus-response link – towards a view of the brain
as an organ that generates hypotheses or fantasies (fantastic: from
Greek Gregory, 1968). This perspective dates back to the notion of
unconscious inference (Helmholtz, 1866/1962) and has been formalised
to cover deep or hierarchical Bayesian inference – about the causes of
our sensations – and how these inferences induce beliefs, movement and
behaviour (Clark, 2013; Dayan, Hinton, & Neal, 1995; Friston, Kilner,
& Harrison, 2006; Hohwy, 2013; Lee & Mumford, 2003).2.1Modern
formulations of the Bayesian brain – such as predictive coding – are
now among the most popular explanations for neuronal message passing
(Clark, 2013; Friston, 2008; Rao & Ballard, 1999; Srinivasan et al.,
1982). Predictive coding is a biologically plausible process theory
for which there is a considerable amount of anatomical and
physiological evidence. In these schemes, neuronal representations –
in higher levels of cortical hierarchies – generate predictions of
representations in lower levels (Friston, 2008; Mumford, 1992; Rao &
Ballard, 1999). These top-down predictions are compared with
representations at the lower level to form a prediction error (usually
associated with the activity of superficial pyramidal cells). The
resulting mismatch signal is passed back up the hierarchy to update
higher representations (associated with the activity of deep pyramidal
cells). This recursive exchange of signals suppresses prediction error
at each and every level to provide a hierarchical explanation for
sensory inputs that enter at the lowest (sensory) level. In
computational terms, neuronal activity encodes beliefs or probability
distributions over states in the world that cause sensations (e.g., my
visual sensations are caused by a In summary, predictive coding
represents a biologically plausible scheme for updating beliefs about
states of the world using sensory samples: see Fig. 2. In this
setting, cortical hierarchies are a neuroanatomical embodiment of how
sensory signals are generated; for example, a face generates surfaces
that generate textures and edges and so on, down to retinal input.
This form of hierarchical inference explains a large number of
anatomical and physiological facts as reviewed elsewhere (Adams,
Shipp, & Friston, 2013; Bastos et al., 2012; Friston, 2008). In brief,
it explains the hierarchical nature of cortical connections; the
prevalence of backward connections and many of the functional and
structural asymmetries in the extrinsic connections that link
hierarchical levels (Zeki & Shipp, 1988). These asymmetries include
the laminar specificity of forward and backward connections, the
prevalence of nonlinear or modulatory backward connections and their
spectral characteristics – with fast (e.g., gamma) activity
predominating in forward connections and slower (e.g., beta)
frequencies that accumulate evidence (prediction errors) ascending
from lower levels.2.2One can regard ascending prediction errors as
broadcasting ‘newsworthy’ information that has yet to be explained by
descending predictions. However, the brain has to select the channels
it listens to – by adjusting the volume or Feldman & Friston, 2010;
Jiang, Summerfield, & Egner, 2013) and has been discussed in terms of
affordance in active inference and action selection (Cisek, 2007;
Frank, Scheres, & Sherman, 2007; Friston et al., 2012). Crucially, the
delicate balance of precision at different hierarchical levels has a
profound effect on veridical inference – and may also offer a formal
understanding of false inference in psychopathology (Adams, Stephan,
Brown, Frith & Friston, 2013; Fletcher & Frith, 2009).In (Friston and
Frith, 2015) we illustrated the role of precision in mediating sensory
attenuation and its necessary role in enabling (open loop) motor
control during action. See also (Brown, Adams, Parees, Edwards, &
Friston, 2013). In brief, this leads to an alternation between sensory
attention and attenuation in the action–perception cycle, which
involves a temporary suspension of attention to the consequences of
acting during the act itself: see (Numminen, Salmelin, & Hari, 1999).
We will use the same approach in this paper to model turn taking
(Wilson & Wilson, 2005) in the switching between speaking (singing)
and listening.2.3Hitherto, we have only considered the role of
predictive coding in perception through minimising surprise or
prediction errors. However, there is another way to minimise
prediction errors; namely, by re-sampling sensory inputs so that they
conform to predictions: in other words, changing sensory inputs by
changing the world through action. This is known as active inference
(Friston, Mattout, & Kilner, 2011). In active inference, action is
regarded as the fulfilment of descending proprioceptive predictions by
classical reflex arcs. In other words, we believe that we will execute
a goal-directed movement and this belief is unpacked hierarchically to
provide proprioceptive, and exteroceptive predictions generated from
our generative or forward model. These predictions are then fulfilled
automatically by minimizing proprioceptive prediction errors at the
level of the spinal cord and cranial nerve nuclei: see (Adams, Shipp,
et al., 2013) and Fig. 2. Mechanistically, descending proprioceptive
predictions provide a target or 2.4The preceding aspects of active
inference are concerned with expectations about hidden states and
causes of sensations and how these expectations minimise prediction
error. However, exactly the same arguments apply to the parameters of
generative models. Model parameters are quantities that do not change
over time and encode causal regularities and associations. Formally,
these are the parameters of the functions in Fig. 2.
Neurobiologically, the parameters of a generative model are thought to
be encoded by synaptic connection strengths and their Bayesian updates
look very much like (experience-dependent) associative plasticity that
mediates short and long-term changes in synaptic connectivity: see the
Appendix and (Friston, 2008) for details. The distinction between
states and parameters of generative models induces the distinction
between perceptual 3This section introduces the simulations of
birdsong that we will use to illustrate active inference and
communication in subsequent sections. The basic idea here is that the
environment unfolds as an ordered sequence of states, whose equations
of motion induce attractor manifolds that contain sensory
trajectories. If we consider the brain has a generative model of these
trajectories, then we would expect to see attractors in neuronal
dynamics that are trying to predict sensory input. This form of
generative model has a number of plausible characteristics:Models
based upon attractors can generate and therefore encode structured
sequences of events, as states flow over different parts of the
attractor manifold (a subset of states to which the flow is
attracted). These sequences can be simple, such as the quasi-periodic
attractors of central pattern generators or can exhibit complicated
sequences of the sort associated with itinerant dynamics (Breakspear &
Stam, 2005; Rabinovich, Huerta, & Laurent, 2008). Furthermore,
hierarchically deployed attractors enable the brain to predict or
represent sequences of sequences. This is because any low-level
attractor embodies a family of trajectories. A natural example here
would be language (Jackendoff, 2002). This means it is possible to
generate and represent sequences of sequences and, by induction
sequences of sequences of sequences etc. This rests upon the states of
neuronal attractors at any cortical level providing control parameters
for attractor dynamics at the level below (Kiebel, von Kriegstein,
Daunizeau, & Friston, 2009). In the example below, we will show how
attractor dynamics furnish generative models of sensory input, which
behave much like real brains, when measured electrophysiologically.We
first reproduce the simulations reported in (Friston and Frith, 2015)
to illustrate the basic nature of the generalised synchrony induced by
predictive coding. We then present new results showing that the
acquisition of this synchrony emerges naturally, when two predictive
coding schemes try to predict each other. This acquisition resolves
the hermeneutic problem by underwriting online inference about the
causes of shared sensory consequences. A more detailed description of
the birdsong model can be found in (Friston & Kiebel, 2009).3.1The
example used here deals with the generation and recognition of
birdsongs. We imagine that birdsongs are produced by two time-varying
states that control the frequency and amplitude of vibrations of the
syrinx of a songbird (Fig. 3). There is an extensive modelling effort
using attractor models to understand the generation of birdsong at the
biomechanical level (Mindlin & Laje, 2005). Here, we use attractors to
provide time-varying control over the resulting sonograms. We drive
the syrinx with two states of a Lorenz attractor, one controlling the
frequency (between two to five KHz) and the other controlling the
amplitude or volume. The parameters of the Lorenz attractor were
chosen to generate a short sequence of chirps every few hundred
milliseconds or so. The Lorenz form for these dynamics is a somewhat
arbitrary choice but provides a ubiquitous model of chaotic dynamics
in the physical (Poland, 1993) and biological (de Boer & Perelson,
1991) sciences.To give the generative model a hierarchical structure,
we placed a second Lorenz attractor, whose dynamics were an order of
magnitude slower, over the first. The first state of the slow
(extrasensory) attractor provided a control parameter for the fast
(sensory) attractor generating the sonogram. In fluid dynamics, this
control parameter is known as a Fig. 3, the Rayleigh number linking
hierarchical levels depends on a model parameter Fig. 4). We will use
this parameter later to demonstrate perceptual learning and closure of
the hermeneutic circle.3.2To illustrate the predictive nature of
predictive coding, perceptual inference was simulated by integrating
the above scheme. Formal details of the generative model and
integration scheme are provided in the equations in Fig. 3 and the
Appendix respectively.1 A more detailed description of this simulation
can be found in a companion paper (Friston and Frith, 2015). In brief,
a sonogram was produced using the above composition of Lorentz
attractors (with Fig. 5.The left panels show the stimulus and percept,
while the right panels show the stimulus and responses to omission of
the last chirps. These results illustrate two important phenomena.
First, there is a vigorous expression of prediction error after the
song terminates prematurely. This reflects the dynamical nature of
inference because, at this point, there is no sensory input to
predict. In other words, the prediction error is generated entirely by
descending predictions. It can be seen that this prediction error
(with a percept but no stimulus) is larger than the prediction error
associated with the third and fourth chirps that are not perceived
(stimulus but no percept). Second, there is a transient percept when
the omitted chirp should have occurred. As noted in (Friston and
Frith, 2015), this simulation of omission-related responses as
measured with ERPs (Bendixen, SanMiguel, & Schröger, 2012) is
particularly interesting, given that non-invasive electromagnetic
signals arise largely from superficial pyramidal cells. These are the
cells thought to encode prediction error (Bastos et al., 2012).4We now
turn to the perceptual coupling or communication by simulating two
birds that can hear themselves (and each other). Each bird listened
for 2 sec, with a low proprioceptive and a high exteroceptive
precision (log-precisions of −8 and 2 respectively) and then sang for
2 sec, with high proprioceptive and attenuated auditory precision
(log-precisions of 0 and -2 respectively). The log-precisions at the
higher level were fixed at 4. Crucially, when one bird was singing the
other was listening. This Wilson & Wilson, 2005) is a natural
consequence of active inference because attending to the consequences
of action interferes with descending predictions about movement –
predictions that are generated before their consequences are evident.
There are many examples of the implicit sensory attenuation during
self-made acts (Hughes, Desantis, & Waszak, 2013). A physiological
illustration can be found in (Agnew, McGettigan, Banks, & Scott,
2013), who show that articulatory movements attenuate auditory
responses to speech using fMRI. Furthermore, recent TMS studies
suggest that the motor system plays an explicit role in semantic
comprehension (Schomers, Kirilina, Weigand, Bajbouj, & Pulvermuller,
2014). We illustrated the importance of sensory attenuation in the
context of simulated birdsong in (Friston and Frith, 2015) by showing
sensorimotor delays – implicit in articulating a song – destroy the
songs dynamical prosody. This means, the birds can only listen or sing
but not do both at the same time.We initialised the simulations with
random expectations. This meant that if the birds cannot hear each
other, the chaotic dynamics implicit in their generative models causes
their expectations to follow divergent trajectories, as shown in
Fig. 6. However, if we move the birds within earshot, so that they can
hear each other, they synchronise almost immediately. See Fig. 7. This
is because the listening bird is immediately entrained by the singing
bird to correctly infer the hidden (dynamical) states generating
sensations. At the end of the first period of listening, the posterior
expectations of both birds approach identical synchrony, which enables
the listening bird to take up the song, following on from where the
other bird left off. This process has many of the hallmarks of Garrod
& Pickering, 2009).Note that the successive epochs of song are not
identical. In other words, the birds are not simply repeating what
they have heard – they are pursuing a narrative prescribed by the
dynamical attractors (central pattern generators) in their generative
models that have been synchronised through sensory exchange. The
example in Fig. 7 highlights the fact that the songs articulated by
both birds have a rich dynamical vocabulary (including frequency
glides, low frequency warbles and amplitude modulated chirps) that is
anticipated and reciprocated during the exchange. This means that the
birds are singing from the same hymn sheet, preserving sequential and
hierarchical structure in their shared narrative. It is this
phenomenon – due simply to generalised (in this case identical)
synchronisation – that we associate with communication.Technically
speaking, this simulation of communication shows that two identical
dynamical systems – that are predicting each other – necessarily show
identical synchronisation. In the language of measure-preserving
dynamical systems, generalised synchronisation implies the existence
of a random dynamical attractor called a Fig. 8). This corresponds to
identical synchronisation. Crucially, the attractor (which contains
the synchronisation manifold) generally has a low measure or volume. A
measure of the attractor's volume is provided by its Sinai, 1959).
Although formally distinct from 4.1In summary, these simulations show
that generalised synchrony is an emergent property of coupling active
inference systems that are trying to predict each other. It is
interesting to consider what is being predicted in this context: the
sensations of both birds are simply the consequences of some
(hierarchically composed and dynamic) hidden states. But what do these
states represent? One might argue that they correspond to some fictive
construct that drives the behaviour of one or other bird to produce
the sensory consequences that are sampled. But which bird? The sensory
consequences are generated, in this setting, by both birds. It
therefore seems plausible to assign these hidden states to both birds
and treat the agency as a contextual factor (that depends on sensory
attention and attenuation). In other words, from the point of view of
one bird, the hidden states are amodal, generating proprioceptive and
exteroceptive consequences that are inferred in exactly the same way
over time; irrespective of whether sensory consequences are generated
by itself or another. The agency or source of sensory consequences is
determined not by the hidden states 5In this final section, we
consider how shared narratives emerge as a natural consequence of
perceptual learning driven by, and only by, the minimisation of
prediction errors or free energy. Using free energy minimisation,
Yildiz, von Kriegstein, and Kiebel (2013) have shown that a hierarchy
of nonlinear dynamical systems can learn speech samples rapidly and
recognize them robustly, even in adverse conditions. Here, we pursue
the same theme but when two birds learn from each other; specifically
focussing on sensorimotor learning during which individuals learn to
vocalise: see Bolhuis & Gahr (2006) for discussion of birdsong
learning. In brief, we repeated the above simulations but reduced the
first bird's parameter. This reduces the sensitivity to top-down
modulation and suppresses the prosody and richness of the lower
attractor. This introduces an asymmetry that precludes identical
synchronisation and induces prediction errors that drive learning.
This learning corresponds to (epoch by epoch) changes in the posterior
expectations of the parameter. In principle, when and only when the
parameters are the same is prediction error (free energy) minimised;
at which point identical synchronisation should emerge. This
effectively closes the hermeneutic cycle to enable precise
communication.Technically, this sort of perceptual learning is a
difficult problem and it took us several tries to find a
parameterisation that could be learned efficiently. This is because
the inference scheme has to estimate unknown parameters in the context
of hidden states that also have to be inferred. Furthermore, the
generative model is not only dynamical and nonlinear but chaotic. The
example we chose is fairly arbitrary but sufficient to show that a
biologically plausible inference scheme can solve this class of
learning problem. Our particular parameterisation focuses on the link
between the sensory and extrasensory attractors and can therefore be
regarded as a translation of a narrative into a dynamical vocabulary.
This means that our two birds start off with a different mapping
between (the same) high-level narrative and the way it is articulated.
To understand each other, they have to learn each other's mapping
(i.e., vocabulary).In detail, the first bird's parameter was reduced
to Fig. 8. The upper panel shows the trajectory of the parameter for
both birds over 32 (1 sec) exchanges. It can be seen that the
parameters of both birds converge towards each other, so that they
both come to articulate a relatively rich sequence of songs. With
successive exchanges, the parameter of the first bird (blue line)
approaches that of the second bird (green line) and synchronisation
emerges (lower right panel). The excursions from the synchronisation
manifold during the first exchange highlight the initial difficulties
the birds have in predicting each other fluently.This acquisition and
maintenance of this rich discourse can be contrasted with the
equivalent learning when the birds cannot hear each other. The
resulting trajectories are shown as dashed lines and demonstrate that
both birds lose the capacity to maintain their Rayleigh number or
dynamical prosody. This is because learning occurs predominantly
during listening, when the precision of auditory prediction errors
(that drive learning) is not attenuated: note the step-like changes in
the parameters. However, when they are listening, each bird only hears
silence, which is best explained by an attractor with a Rayleigh
number of zero (see Fig. 4). In this situation, both birds emit
progressively simpler, low-frequency warbles that disappear by about
the 16th exchange (results not shown).Taken together, these
simulations illustrate the circular causality inherent in
communicative inference and learning. In other words, one needs to
infer or predict a structured sensory exchange before learning can
occur; while learning is necessary to render sensory exchanges
predictable. Furthermore, although the second bird appears to teach
the first bird when they hear each other, both are teaching each other
– as evidenced by the fact that the second bird ‘forgot’ how to sing
when it could not hear the first. The simulations should not be taken
as proof of concept of these points; they simply illustrate the sorts
of phenomena that can emerge when dynamical systems are trying to
predict and learn from each other.5.1This section has illustrated
perceptual learning as a key process in facilitating communication and
generalised synchrony in coupled active inference schemes. In this
context, prediction errors implicit in the (neurobiologically
plausible) predictive coding implementation of active inference are
driving both expectations about hidden states and the learning of
model parameters. This means there are two hermeneutic timescales: the
first subtending synchronisation and perceptual inference about hidden
states of the world and the second slower perceptual learning of the
parameters governing fluctuations in the hidden states. The endpoint
is a mutual predictability that is underwritten by a convergence of
the (parameters of) generative models subtending predictions. Although
a simple example, these simulations provide proof of principle that
perceptual learning is a sufficient explanation for the emergence of
generalised synchrony.6The treatment above builds on the ideas
introduced by (Friston and Frith, 2015); namely, that generalised
synchrony – or synchronisation of chaos – provides a formal metaphor
for communication and is a natural consequence of active inference.
The contribution of the current paper is to show that the same
principle (minimisation of free energy or prediction error), also
explains the convergent evolution of hierarchical models that generate
mutually sympathetic predictions. We have considered this convergence
in terms of perceptual learning that closes the hermeneutic
cycle.There are many issues that we have not considered in the domain
of neural hermeneutics and communication. Among these is the
possibility that we are equipped with multiple generative models that
can be deployed depending upon the situation in which we find
ourselves, or the person that we are communicating with. In this
instance, the selection of an appropriate generative model – that
approximates the model selected by you – would be better understood in
terms of Bayesian model selection or averaging (FitzGerald, Dolan, &
Friston, 2014). This is an interesting possibility that speaks to
inferring the context in which we are communicating and who we are
communicating with. This represents another (hierarchical) inference
problem. The model selection perspective is interesting because, if
correct, it implies a multilateral internal model of how we behave
that is entirely dependent upon who we are communicating with. In
turn, this begs the question of agency and how it is represented in
generative models. For example, if our conceptual narratives are
context-sensitive and truly shared, am I the same person (in my mind)
when speaking to you, as opposed to somebody else? Furthermore, if I
do not have a narrative (or appropriate mapping to a vocabulary) that
corresponds to your narrative (or mapping), will I ever be able to
communicate with you? This is where perceptual learning comes into its
own; enabling the acquisition of new narratives (and vocabularies) or
repurposing of existing models; e.g., (Adank, Hagoort, & Bekkering,
2010; Skoe, Krizman, Spitzer, & Kraus, 2014). However – as anyone who
has tried to learn a foreign language can testify – learning can be a
difficult and slow process, especially for Englishmen like us.The
authors declare no conflicts of interest.